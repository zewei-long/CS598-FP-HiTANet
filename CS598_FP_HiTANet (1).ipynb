{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS598-FP-HiTANet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import math\n",
        "import torch.nn.init as init\n",
        "import copy\n",
        "import os\n",
        "import pickle\n",
        "import time\n",
        "import random\n",
        "import shutil\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from torch.autograd import Variable"
      ],
      "metadata": {
        "id": "xGMPzAo_xHSq"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "transformer architecture"
      ],
      "metadata": {
        "id": "_1bed9a4HjTn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Embedding(torch.nn.Embedding):\n",
        "\n",
        "    def __init__(self, num_embeddings, embedding_dim, padding_idx=None,\n",
        "                 max_norm=None, norm_type=2., scale_grad_by_freq=False,\n",
        "                 sparse=False, _weight=None):\n",
        "        super(Embedding, self).__init__(num_embeddings, embedding_dim, padding_idx=padding_idx,\n",
        "                                        max_norm=max_norm, norm_type=norm_type, scale_grad_by_freq=scale_grad_by_freq,\n",
        "                                        sparse=sparse, _weight=_weight)\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
        "        if self.padding_idx is not None:\n",
        "            with torch.no_grad():\n",
        "                self.weight[self.padding_idx].fill_(0)\n",
        "\n",
        "\n",
        "class ScaledDotProductAttention(nn.Module):\n",
        "    \"\"\"Scaled dot-product attention mechanism.\"\"\"\n",
        "\n",
        "    def __init__(self, attention_dropout=0.0):\n",
        "        super(ScaledDotProductAttention, self).__init__()\n",
        "        self.dropout = nn.Dropout(attention_dropout)\n",
        "        self.softmax = nn.Softmax(dim=2)\n",
        "\n",
        "    def forward(self, q, k, v, scale=None, attn_mask=None):\n",
        "        attention = torch.bmm(q, k.transpose(1, 2))\n",
        "        if scale:\n",
        "            attention = attention * scale\n",
        "        if attn_mask is not None:\n",
        "            attention = attention.masked_fill_(attn_mask, -np.inf)\n",
        "        attention = self.softmax(attention)\n",
        "        attention = self.dropout(attention)\n",
        "        context = torch.bmm(attention, v)\n",
        "        return context, attention\n",
        "\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, max_seq_len):\n",
        "\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "\n",
        "\n",
        "        position_encoding = np.array([\n",
        "            [pos / np.power(10000, 2.0 * (j // 2) / d_model) for j in range(d_model)]\n",
        "            for pos in range(max_seq_len)])\n",
        "\n",
        "        position_encoding[:, 0::2] = np.sin(position_encoding[:, 0::2])\n",
        "        position_encoding[:, 1::2] = np.cos(position_encoding[:, 1::2])\n",
        "        position_encoding = torch.from_numpy(position_encoding.astype(np.float32))\n",
        "\n",
        "        pad_row = torch.zeros([1, d_model])\n",
        "        position_encoding = torch.cat((pad_row, position_encoding))\n",
        "\n",
        "        self.position_encoding = nn.Embedding(max_seq_len + 1, d_model)\n",
        "        self.position_encoding.weight = nn.Parameter(position_encoding,\n",
        "                                                     requires_grad=False)\n",
        "\n",
        "    def forward(self, input_len):\n",
        "\n",
        "\n",
        "        max_len = torch.max(input_len)\n",
        "        tensor = torch.cuda.LongTensor if input_len.is_cuda else torch.LongTensor\n",
        "\n",
        "        pos = np.zeros([len(input_len), max_len])\n",
        "        for ind, length in enumerate(input_len):\n",
        "            for pos_ind in range(1, length + 1):\n",
        "                pos[ind, pos_ind - 1] = pos_ind\n",
        "        input_pos = tensor(pos)\n",
        "        return self.position_encoding(input_pos), input_pos\n",
        "\n",
        "\n",
        "class PositionalWiseFeedForward(nn.Module):\n",
        "    def __init__(self, model_dim=512, ffn_dim=2048, dropout=0.0):\n",
        "        super(PositionalWiseFeedForward, self).__init__()\n",
        "        self.w1 = nn.Conv1d(model_dim, ffn_dim, 1)\n",
        "        self.w2 = nn.Conv1d(ffn_dim, model_dim, 1)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.layer_norm = nn.LayerNorm(model_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = x.transpose(1, 2)\n",
        "        output = self.w2(F.relu(self.w1(output)))\n",
        "        output = self.dropout(output.transpose(1, 2))\n",
        "\n",
        "        # add residual and norm layer\n",
        "        output = self.layer_norm(x + output)\n",
        "        return output\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, model_dim=512, num_heads=8, dropout=0.0):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.dim_per_head = model_dim // num_heads\n",
        "        self.num_heads = num_heads\n",
        "        self.linear_k = nn.Linear(model_dim, self.dim_per_head * num_heads)\n",
        "        self.linear_v = nn.Linear(model_dim, self.dim_per_head * num_heads)\n",
        "        self.linear_q = nn.Linear(model_dim, self.dim_per_head * num_heads)\n",
        "\n",
        "        self.dot_product_attention = ScaledDotProductAttention(dropout)\n",
        "        self.linear_final = nn.Linear(model_dim, model_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.layer_norm = nn.LayerNorm(model_dim)\n",
        "\n",
        "    def forward(self, key, value, query, attn_mask=None):\n",
        "        residual = query\n",
        "\n",
        "        dim_per_head = self.dim_per_head\n",
        "        num_heads = self.num_heads\n",
        "        batch_size = key.size(0)\n",
        "\n",
        "        # linear projection\n",
        "        key = self.linear_k(key)\n",
        "        value = self.linear_v(value)\n",
        "        query = self.linear_q(query)\n",
        "\n",
        "        # split by heads\n",
        "        key = key.view(batch_size * num_heads, -1, dim_per_head)\n",
        "        value = value.view(batch_size * num_heads, -1, dim_per_head)\n",
        "        query = query.view(batch_size * num_heads, -1, dim_per_head)\n",
        "\n",
        "        if attn_mask is not None:\n",
        "            attn_mask = attn_mask.repeat(num_heads, 1, 1)\n",
        "        # scaled dot product attention\n",
        "        scale = (key.size(-1) // num_heads) ** -0.5\n",
        "        context, attention = self.dot_product_attention(\n",
        "            query, key, value, scale, attn_mask)\n",
        "\n",
        "        # concat heads\n",
        "        context = context.view(batch_size, -1, dim_per_head * num_heads)\n",
        "\n",
        "        # final linear projection\n",
        "        output = self.linear_final(context)\n",
        "\n",
        "        # dropout\n",
        "        output = self.dropout(output)\n",
        "\n",
        "        # add residual and norm layer\n",
        "        output = self.layer_norm(residual + output)\n",
        "\n",
        "        return output, attention\n",
        "\n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, model_dim=512, num_heads=8, ffn_dim=2018, dropout=0.0):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "\n",
        "        self.attention = MultiHeadAttention(model_dim, num_heads, dropout)\n",
        "        self.feed_forward = PositionalWiseFeedForward(model_dim, ffn_dim, dropout)\n",
        "\n",
        "    def forward(self, inputs, attn_mask=None):\n",
        "        # self attention\n",
        "        context, attention = self.attention(inputs, inputs, inputs, attn_mask)\n",
        "\n",
        "        # feed forward network\n",
        "        output = self.feed_forward(context)\n",
        "\n",
        "        return output, attention\n",
        "\n",
        "\n",
        "def padding_mask(seq_k, seq_q):\n",
        "    len_q = seq_q.size(1)\n",
        "    pad_mask = seq_k.eq(0)\n",
        "    pad_mask = pad_mask.unsqueeze(1).expand(-1, len_q, -1)  # shape [B, L_q, L_k]\n",
        "    return pad_mask\n",
        "\n",
        "\n",
        "def padding_mask_sand(seq_k, seq_q):\n",
        "    len_q = seq_q.size(1)\n",
        "    pad_mask = seq_k.eq(0)\n",
        "    pad_mask = pad_mask.unsqueeze(1).expand(-1, len_q, -1)  # shape [B, L_q, L_k]\n",
        "    return pad_mask\n",
        "\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self,\n",
        "                 vocab_size,\n",
        "                 max_seq_len,\n",
        "                 num_layers=1,\n",
        "                 model_dim=256,\n",
        "                 num_heads=4,\n",
        "                 ffn_dim=1024,\n",
        "                 dropout=0.0):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.encoder_layers = nn.ModuleList(\n",
        "            [EncoderLayer(model_dim, num_heads, ffn_dim, dropout) for _ in\n",
        "             range(num_layers)])\n",
        "        self.pre_embedding = Embedding(vocab_size, model_dim)\n",
        "        self.bias_embedding = torch.nn.Parameter(torch.Tensor(model_dim))\n",
        "        bound = 1 / math.sqrt(vocab_size)\n",
        "        init.uniform_(self.bias_embedding, -bound, bound)\n",
        "\n",
        "        # self.weight_layer = torch.nn.Linear(model_dim, 1)\n",
        "        self.pos_embedding = PositionalEncoding(model_dim, max_seq_len)\n",
        "        self.time_layer = torch.nn.Linear(64, 256)\n",
        "        self.selection_layer = torch.nn.Linear(1, 64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, diagnosis_codes, mask, mask_code, seq_time_step, input_len):\n",
        "        seq_time_step = torch.Tensor(seq_time_step).cuda().unsqueeze(2) / 180\n",
        "        time_feature = 1 - self.tanh(torch.pow(self.selection_layer(seq_time_step), 2))\n",
        "        time_feature = self.time_layer(time_feature)\n",
        "        output = (self.pre_embedding(diagnosis_codes) * mask_code).sum(dim=2) + self.bias_embedding\n",
        "        output += time_feature\n",
        "        output_pos, ind_pos = self.pos_embedding(input_len.unsqueeze(1))\n",
        "        output += output_pos\n",
        "        self_attention_mask = padding_mask(ind_pos, ind_pos)\n",
        "\n",
        "        attentions = []\n",
        "        outputs = []\n",
        "        for encoder in self.encoder_layers:\n",
        "            output, attention = encoder(output, self_attention_mask)\n",
        "            attentions.append(attention)\n",
        "            outputs.append(output)\n",
        "        return output\n",
        "\n",
        "\n",
        "def adjust_input(batch_diagnosis_codes, batch_time_step, max_len, n_diagnosis_codes):\n",
        "    batch_time_step = copy.deepcopy(batch_time_step)\n",
        "    batch_diagnosis_codes = copy.deepcopy(batch_diagnosis_codes)\n",
        "    for ind in range(len(batch_diagnosis_codes)):\n",
        "        if len(batch_diagnosis_codes[ind]) > max_len:\n",
        "            batch_diagnosis_codes[ind] = batch_diagnosis_codes[ind][-(max_len):]\n",
        "            batch_time_step[ind] = batch_time_step[ind][-(max_len):]\n",
        "        batch_time_step[ind].append(0)\n",
        "        batch_diagnosis_codes[ind].append([n_diagnosis_codes - 1])\n",
        "    return batch_diagnosis_codes, batch_time_step\n",
        "\n",
        "class TimeEncoder(nn.Module):\n",
        "    def __init__(self, batch_size):\n",
        "        super(TimeEncoder, self).__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.selection_layer = torch.nn.Linear(1, 64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.tanh = nn.Tanh()\n",
        "        self.weight_layer = torch.nn.Linear(64, 64)\n",
        "\n",
        "    def forward(self, seq_time_step, final_queries, options, mask):\n",
        "        if options['use_gpu']:\n",
        "            seq_time_step = torch.Tensor(seq_time_step).unsqueeze(2).cuda() / 180\n",
        "        else:\n",
        "            seq_time_step = torch.Tensor(seq_time_step).unsqueeze(2) / 180\n",
        "        selection_feature = 1 - self.tanh(torch.pow(self.selection_layer(seq_time_step), 2))\n",
        "        selection_feature = self.relu(self.weight_layer(selection_feature))\n",
        "        selection_feature = torch.sum(selection_feature * final_queries, 2, keepdim=True) / 8\n",
        "        selection_feature = selection_feature.masked_fill_(mask, -np.inf)\n",
        "        # time_weights = self.weight_layer(selection_feature)\n",
        "        return torch.softmax(selection_feature, 1)\n",
        "\n",
        "\n",
        "class TransformerTime(nn.Module):\n",
        "    def __init__(self, n_diagnosis_codes, batch_size, options):\n",
        "        super(TransformerTime, self).__init__()\n",
        "        # self.prior_encoder = PriorEncoder(batch_size, options)\n",
        "        self.time_encoder = TimeEncoder(batch_size)\n",
        "        self.feature_encoder = Encoder(options['n_diagnosis_codes'] + 1, 51, num_layers=options['layer'])\n",
        "        self.self_layer = torch.nn.Linear(256, 1)\n",
        "        self.classify_layer = torch.nn.Linear(256, 2)\n",
        "        self.quiry_layer = torch.nn.Linear(256, 64)\n",
        "        self.quiry_weight_layer = torch.nn.Linear(256, 2)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        # dropout layer\n",
        "        dropout_rate = options['dropout_rate']\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "    def get_self_attention(self, features, query, mask):\n",
        "        attention = torch.softmax(self.self_layer(features).masked_fill(mask, -np.inf), dim=1)\n",
        "        return attention\n",
        "\n",
        "    def forward(self, seq_dignosis_codes, seq_time_step, batch_labels, options, maxlen):\n",
        "        seq_time_step = np.array(list(pad_time(seq_time_step, options)))\n",
        "        lengths = torch.from_numpy(np.array([len(seq) for seq in seq_dignosis_codes])).cuda()\n",
        "        diagnosis_codes, labels, mask, mask_final, mask_code = pad_matrix_new(seq_dignosis_codes,\n",
        "                                                                                        batch_labels, options)\n",
        "        if options['use_gpu']:\n",
        "            diagnosis_codes = torch.LongTensor(diagnosis_codes).cuda()\n",
        "            mask_mult = torch.BoolTensor(1-mask).unsqueeze(2).cuda()\n",
        "            mask_final = torch.Tensor(mask_final).unsqueeze(2).cuda()\n",
        "            mask_code = torch.Tensor(mask_code).unsqueeze(3).cuda()\n",
        "        else:\n",
        "            diagnosis_codes = torch.LongTensor(diagnosis_codes)\n",
        "            mask_mult = torch.BoolTensor(1-mask).unsqueeze(2)\n",
        "            mask_final = torch.Tensor(mask_final).unsqueeze(2)\n",
        "            mask_code = torch.Tensor(mask_code).unsqueeze(3)\n",
        "        features = self.feature_encoder(diagnosis_codes, mask_mult, mask_code, seq_time_step, lengths)\n",
        "        final_statues = features * mask_final\n",
        "        final_statues = final_statues.sum(1, keepdim=True)\n",
        "        quiryes = self.relu(self.quiry_layer(final_statues))\n",
        "\n",
        "        self_weight = self.get_self_attention(features, quiryes, mask_mult)\n",
        "        time_weight = self.time_encoder(seq_time_step, quiryes, options, mask_mult)\n",
        "        attention_weight = torch.softmax(self.quiry_weight_layer(final_statues), 2)\n",
        "\n",
        "        total_weight = torch.cat((time_weight, self_weight), 2)\n",
        "        total_weight = torch.sum(total_weight * attention_weight, 2, keepdim=True)\n",
        "        total_weight = total_weight / (torch.sum(total_weight, 1, keepdim=True) + 1e-5)\n",
        "        weighted_features = features * total_weight\n",
        "        averaged_features = torch.sum(weighted_features, 1)\n",
        "        averaged_features = self.dropout(averaged_features)\n",
        "        predictions = self.classify_layer(averaged_features)\n",
        "        labels = torch.LongTensor(labels)\n",
        "        if options['use_gpu']:\n",
        "            labels = labels.cuda()\n",
        "        return predictions, labels, self_weight"
      ],
      "metadata": {
        "id": "LEbS6-LdZr3w"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLT(nn.Module):\n",
        "    def __init__(self,\n",
        "                 vocab_size,\n",
        "                 max_seq_len,\n",
        "                 num_layers=1,\n",
        "                 model_dim=256,\n",
        "                 num_heads=4,\n",
        "                 ffn_dim=1024,\n",
        "                 dropout=0.0):\n",
        "        super(EncoderLT, self).__init__()\n",
        "\n",
        "        self.encoder_layers = nn.ModuleList(\n",
        "            [EncoderLayer(model_dim, num_heads, ffn_dim, dropout) for _ in\n",
        "             range(num_layers)])\n",
        "        self.pre_embedding = Embedding(vocab_size, model_dim)\n",
        "        self.bias_embedding = torch.nn.Parameter(torch.Tensor(model_dim))\n",
        "        bound = 1 / math.sqrt(vocab_size)\n",
        "        init.uniform_(self.bias_embedding, -bound, bound)\n",
        "\n",
        "        # self.weight_layer = torch.nn.Linear(model_dim, 1)\n",
        "        self.pos_embedding = PositionalEncoding(model_dim, max_seq_len)\n",
        "        # self.time_layer = torch.nn.Linear(64, model_dim)\n",
        "        self.selection_layer = torch.nn.Linear(1, 64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, diagnosis_codes, mask, mask_code, seq_time_step, input_len):\n",
        "        # seq_time_step = torch.Tensor(seq_time_step).cuda().unsqueeze(2)/180\n",
        "        # time_feature = 1 - self.tanh(torch.pow(self.selection_layer(seq_time_step), 2))\n",
        "        # time_feature = self.time_layer(time_feature)\n",
        "        output = (self.pre_embedding(diagnosis_codes) * mask_code).sum(dim=2) + self.bias_embedding\n",
        "        # output += time_feature\n",
        "        output_pos, ind_pos = self.pos_embedding(input_len.unsqueeze(1))\n",
        "        output += output_pos\n",
        "        self_attention_mask = padding_mask(ind_pos, ind_pos)\n",
        "\n",
        "        attentions = []\n",
        "        outputs = []\n",
        "        for encoder in self.encoder_layers:\n",
        "            output, attention = encoder(output, self_attention_mask)\n",
        "            attentions.append(attention)\n",
        "            outputs.append(output)\n",
        "        # weight = torch.softmax(self.weight_layer(outputs[-1]), dim=1)\n",
        "        # weight = weight * mask - 255 * (1 - mask)\n",
        "        return output\n",
        "\n",
        "class TransformerLT(nn.Module):\n",
        "    def __init__(self, n_diagnosis_codes, batch_size, options):\n",
        "        super(TransformerLT, self).__init__()\n",
        "        # self.prior_encoder = PriorEncoder(batch_size, options)\n",
        "        self.time_encoder = TimeEncoder(batch_size)\n",
        "        self.feature_encoder = EncoderLT(options['n_diagnosis_codes'] + 1, 51, num_layers=options['layer'])\n",
        "        self.self_layer = torch.nn.Linear(256, 1)\n",
        "        self.classify_layer = torch.nn.Linear(256, 2)\n",
        "        self.quiry_layer = torch.nn.Linear(256, 64)\n",
        "        self.quiry_weight_layer = torch.nn.Linear(256, 2)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        # dropout layer\n",
        "        dropout_rate = options['dropout_rate']\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "    def get_self_attention(self, features, query, mask):\n",
        "        attention = torch.softmax(self.self_layer(features).masked_fill_(mask, -np.inf), dim=1)\n",
        "        # attention = torch.sum(key * query, 2, keepdim=True) / 8\n",
        "        return attention\n",
        "\n",
        "    def forward(self, seq_dignosis_codes, seq_time_step, batch_labels, options, maxlen):\n",
        "        seq_time_step = np.array(list(pad_time(seq_time_step, options)))\n",
        "        lengths = torch.from_numpy(np.array([len(seq) for seq in seq_dignosis_codes])).cuda()\n",
        "        diagnosis_codes, labels, mask, mask_final, mask_code = pad_matrix_new(seq_dignosis_codes,\n",
        "                                                                                        batch_labels, options)\n",
        "        if options['use_gpu']:\n",
        "            diagnosis_codes = torch.LongTensor(diagnosis_codes).cuda()\n",
        "            mask_mult = torch.BoolTensor(1 - mask).unsqueeze(2).cuda()\n",
        "            mask_final = torch.Tensor(mask_final).unsqueeze(2).cuda()\n",
        "            mask_code = torch.Tensor(mask_code).unsqueeze(3).cuda()\n",
        "        else:\n",
        "            diagnosis_codes = torch.LongTensor(diagnosis_codes)\n",
        "            mask_mult = torch.BoolTensor(1 - mask).unsqueeze(2)\n",
        "            mask_final = torch.Tensor(mask_final).unsqueeze(2)\n",
        "            mask_code = torch.Tensor(mask_code).unsqueeze(3)\n",
        "        features = self.feature_encoder(diagnosis_codes, mask_mult, mask_code, seq_time_step, lengths)\n",
        "        final_statues = features * mask_final\n",
        "        final_statues = final_statues.sum(1, keepdim=True)\n",
        "        quiryes = self.relu(self.quiry_layer(final_statues))\n",
        "\n",
        "        # prior_weight = self.prior_encoder(seq_dignosis_codes, maxlen, quiryes, options, mask_mult)\n",
        "        self_weight = self.get_self_attention(features, quiryes, mask_mult)\n",
        "        time_weight = self.time_encoder(seq_time_step, quiryes, options, mask_mult)\n",
        "        attention_weight = torch.softmax(self.quiry_weight_layer(final_statues), 2)\n",
        "\n",
        "        total_weight = torch.cat((time_weight, self_weight), 2)\n",
        "        total_weight = torch.sum(total_weight * attention_weight, 2, keepdim=True)\n",
        "        total_weight = total_weight / (torch.sum(total_weight, 1, keepdim=True) + 1e-5)\n",
        "        weighted_features = features * total_weight\n",
        "        averaged_features = torch.sum(weighted_features, 1)\n",
        "        averaged_features = self.dropout(averaged_features)\n",
        "        predictions = self.classify_layer(averaged_features)\n",
        "        labels = torch.LongTensor(labels)\n",
        "        if options['use_gpu']:\n",
        "            labels = labels.cuda()\n",
        "        return predictions, labels, self_weight"
      ],
      "metadata": {
        "id": "EDOZhzw1xrv4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderGT(nn.Module):\n",
        "    def __init__(self,\n",
        "                 vocab_size,\n",
        "                 max_seq_len,\n",
        "                 num_layers=1,\n",
        "                 model_dim=256,\n",
        "                 num_heads=4,\n",
        "                 ffn_dim=1024,\n",
        "                 dropout=0.0):\n",
        "        super(EncoderGT, self).__init__()\n",
        "\n",
        "        self.encoder_layers = nn.ModuleList(\n",
        "            [EncoderLayer(model_dim, num_heads, ffn_dim, dropout) for _ in\n",
        "             range(num_layers)])\n",
        "        self.pre_embedding = Embedding(vocab_size, model_dim)\n",
        "        self.bias_embedding = torch.nn.Parameter(torch.Tensor(model_dim))\n",
        "        bound = 1 / math.sqrt(vocab_size)\n",
        "        init.uniform_(self.bias_embedding, -bound, bound)\n",
        "\n",
        "        # self.weight_layer = torch.nn.Linear(model_dim, 1)\n",
        "        self.pos_embedding = PositionalEncoding(model_dim, max_seq_len)\n",
        "        self.time_layer = torch.nn.Linear(64, 256)\n",
        "        self.selection_layer = torch.nn.Linear(1, 64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, diagnosis_codes, mask, mask_code, seq_time_step, input_len):\n",
        "        seq_time_step = torch.Tensor(seq_time_step).cuda().unsqueeze(2) / 180\n",
        "        time_feature = 1 - self.tanh(torch.pow(self.selection_layer(seq_time_step), 2))\n",
        "        time_feature = self.time_layer(time_feature)\n",
        "        output = (self.pre_embedding(diagnosis_codes) * mask_code).sum(dim=2) + self.bias_embedding\n",
        "        output += time_feature\n",
        "        output_pos, ind_pos = self.pos_embedding(input_len.unsqueeze(1))\n",
        "        output += output_pos\n",
        "        self_attention_mask = padding_mask(ind_pos, ind_pos)\n",
        "\n",
        "        attentions = []\n",
        "        outputs = []\n",
        "        for encoder in self.encoder_layers:\n",
        "            output, attention = encoder(output, self_attention_mask)\n",
        "            attentions.append(attention)\n",
        "            outputs.append(output)\n",
        "        # weight = torch.softmax(self.weight_layer(outputs[-1]), dim=1)\n",
        "        # weight = weight * mask - 255 * (1 - mask)\n",
        "        return output\n",
        "\n",
        "class TransformerGT(nn.Module):\n",
        "    def __init__(self, n_diagnosis_codes, batch_size, options):\n",
        "        super(TransformerGT, self).__init__()\n",
        "        # self.prior_encoder = PriorEncoder(batch_size, options)\n",
        "        self.time_encoder = TimeEncoder(batch_size)\n",
        "        self.feature_encoder = EncoderGT(options['n_diagnosis_codes'] + 1, 51, num_layers=options['layer'])\n",
        "        self.self_layer = torch.nn.Linear(256, 1)\n",
        "        self.classify_layer = torch.nn.Linear(256, 2)\n",
        "        self.quiry_layer = torch.nn.Linear(256, 64)\n",
        "        self.quiry_weight_layer = torch.nn.Linear(256, 2)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        # dropout layer\n",
        "        dropout_rate = options['dropout_rate']\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "    def get_self_attention(self, features, query, mask):\n",
        "        attention = torch.softmax(self.self_layer(features).masked_fill_(mask, -np.inf), dim=1)\n",
        "        # attention = torch.sum(key * query, 2, keepdim=True) / 8\n",
        "        return attention\n",
        "\n",
        "    def forward(self, seq_dignosis_codes, seq_time_step, batch_labels, options, maxlen):\n",
        "        seq_time_step = np.array(list(pad_time(seq_time_step, options)))\n",
        "        lengths = torch.from_numpy(np.array([len(seq) for seq in seq_dignosis_codes])).cuda()\n",
        "        diagnosis_codes, labels, mask, mask_final, mask_code = pad_matrix_new(seq_dignosis_codes,\n",
        "                                                                                        batch_labels, options)\n",
        "        if options['use_gpu']:\n",
        "            diagnosis_codes = torch.LongTensor(diagnosis_codes).cuda()\n",
        "            mask_mult = torch.BoolTensor(1 - mask).unsqueeze(2).cuda()\n",
        "            mask_final = torch.Tensor(mask_final).unsqueeze(2).cuda()\n",
        "            mask_code = torch.Tensor(mask_code).unsqueeze(3).cuda()\n",
        "        else:\n",
        "            diagnosis_codes = torch.LongTensor(diagnosis_codes)\n",
        "            mask_mult = torch.BoolTensor(1 - mask).unsqueeze(2)\n",
        "            mask_final = torch.Tensor(mask_final).unsqueeze(2)\n",
        "            mask_code = torch.Tensor(mask_code).unsqueeze(3)\n",
        "        features = self.feature_encoder(diagnosis_codes, mask_mult, mask_code, seq_time_step, lengths)\n",
        "        final_statues = features * mask_final\n",
        "        final_statues = final_statues.sum(1, keepdim=True)\n",
        "        quiryes = self.relu(self.quiry_layer(final_statues))\n",
        "\n",
        "        # prior_weight = self.prior_encoder(seq_dignosis_codes, maxlen, quiryes, options, mask_mult)\n",
        "        self_weight = self.get_self_attention(features, quiryes, mask_mult)\n",
        "        # time_weight = self.time_encoder(seq_time_step, quiryes, options, mask_mult)\n",
        "        # attention_weight = torch.softmax(self.quiry_weight_layer(final_statues), 2)\n",
        "\n",
        "        # total_weight = torch.cat((time_weight, self_weight), 2)\n",
        "        total_weight = self_weight\n",
        "        total_weight = total_weight / (torch.sum(total_weight, 1, keepdim=True) + 1e-5)\n",
        "        weighted_features = features * total_weight\n",
        "        averaged_features = torch.sum(weighted_features, 1)\n",
        "        averaged_features = self.dropout(averaged_features)\n",
        "        predictions = self.classify_layer(averaged_features)\n",
        "        labels = torch.LongTensor(labels)\n",
        "        if options['use_gpu']:\n",
        "            labels = labels.cuda()\n",
        "        return predictions, labels, self_weight"
      ],
      "metadata": {
        "id": "y8y5ykHnyMSA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "about data processing before training"
      ],
      "metadata": {
        "id": "c_6WJFDcH6AO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(training_file, testing_file):\n",
        "    train = np.array(pickle.load(open(training_file, 'rb')))\n",
        "    # validate = np.array(pickle.load(open(validation_file, 'rb')))\n",
        "    test = np.array(pickle.load(open(testing_file, 'rb')))\n",
        "    return train, test\n",
        "\n",
        "def cut_data(training_file, validation_file, testing_file):\n",
        "    train = list(pickle.load(open(training_file, 'rb')))\n",
        "    validate = list(pickle.load(open(validation_file, 'rb')))\n",
        "    test = list(pickle.load(open(testing_file, 'rb')))\n",
        "    for dataset in [train, validate, test]:\n",
        "        dataset[0] = dataset[0][0: len(dataset[0]) // 18]\n",
        "        dataset[1] = dataset[1][0: len(dataset[1]) // 18]\n",
        "        dataset[2] = dataset[2][0: len(dataset[2]) // 18]\n",
        "    return train, validate, test\n",
        "\n",
        "\n",
        "def pad_time(seq_time_step, options):\n",
        "    lengths = np.array([len(seq) for seq in seq_time_step])\n",
        "    maxlen = np.max(lengths)\n",
        "    for k in range(len(seq_time_step)):\n",
        "        while len(seq_time_step[k]) < maxlen:\n",
        "            seq_time_step[k].append(100000)\n",
        "\n",
        "    return seq_time_step\n",
        "\n",
        "def pad_matrix_new(seq_diagnosis_codes, seq_labels, options):\n",
        "    lengths = np.array([len(seq) for seq in seq_diagnosis_codes])\n",
        "    n_samples = len(seq_diagnosis_codes)\n",
        "    n_diagnosis_codes = options['n_diagnosis_codes']\n",
        "    maxlen = np.max(lengths)\n",
        "    lengths_code = []\n",
        "    for seq in seq_diagnosis_codes:\n",
        "        for code_set in seq:\n",
        "            lengths_code.append(len(code_set))\n",
        "    lengths_code = np.array(lengths_code)\n",
        "    maxcode = np.max(lengths_code)\n",
        "\n",
        "    batch_diagnosis_codes = np.zeros((n_samples, maxlen, maxcode), dtype=np.int64) + options['n_diagnosis_codes']\n",
        "    batch_mask = np.zeros((n_samples, maxlen), dtype=np.float32)\n",
        "    batch_mask_code = np.zeros((n_samples, maxlen, maxcode), dtype=np.float32)\n",
        "    batch_mask_final = np.zeros((n_samples, maxlen), dtype=np.float32)\n",
        "\n",
        "    for bid, seq in enumerate(seq_diagnosis_codes):\n",
        "        for pid, subseq in enumerate(seq):\n",
        "            for tid, code in enumerate(subseq):\n",
        "                batch_diagnosis_codes[bid, pid, tid] = code\n",
        "                batch_mask_code[bid, pid, tid] = 1\n",
        "\n",
        "\n",
        "    for i in range(n_samples):\n",
        "        batch_mask[i, 0:lengths[i]-1] = 1\n",
        "        max_visit = lengths[i] - 1\n",
        "        batch_mask_final[i, max_visit] = 1\n",
        "\n",
        "    batch_labels = np.array(seq_labels, dtype=np.int64)\n",
        "\n",
        "    return batch_diagnosis_codes, batch_labels, batch_mask, batch_mask_final, batch_mask_code\n",
        "\n",
        "\n",
        "def calculate_cost_tran(model, data, options, max_len, loss_function=F.cross_entropy):\n",
        "    model.eval()\n",
        "    batch_size = options['batch_size']\n",
        "    n_batches = int(np.ceil(float(len(data[0])) / float(batch_size)))\n",
        "    cost_sum = 0.0\n",
        "\n",
        "    for index in range(n_batches):\n",
        "        batch_diagnosis_codes = data[0][batch_size * index: batch_size * (index + 1)]\n",
        "        batch_time_step = data[2][batch_size * index: batch_size * (index + 1)]\n",
        "        batch_diagnosis_codes, batch_time_step = adjust_input(batch_diagnosis_codes, batch_time_step, max_len, options['n_diagnosis_codes'])\n",
        "        batch_labels = data[1][batch_size * index: batch_size * (index + 1)]\n",
        "        lengths = np.array([len(seq) for seq in batch_diagnosis_codes])\n",
        "        maxlen = np.max(lengths)\n",
        "        logit, labels, self_attention = model(batch_diagnosis_codes, batch_time_step, batch_labels, options, maxlen)\n",
        "        loss = loss_function(logit, labels)\n",
        "        cost_sum += loss.cpu().data.numpy()\n",
        "    model.train()\n",
        "    return cost_sum / n_batches\n",
        "\n",
        "\n",
        "def adjust_input(batch_diagnosis_codes, batch_time_step, max_len, n_diagnosis_codes):\n",
        "    batch_time_step = copy.deepcopy(batch_time_step)\n",
        "    batch_diagnosis_codes = copy.deepcopy(batch_diagnosis_codes)\n",
        "    for ind in range(len(batch_diagnosis_codes)):\n",
        "        if len(batch_diagnosis_codes[ind]) > max_len:\n",
        "            batch_diagnosis_codes[ind] = batch_diagnosis_codes[ind][-(max_len):]\n",
        "            batch_time_step[ind] = batch_time_step[ind][-(max_len):]\n",
        "        batch_time_step[ind].append(0)\n",
        "        batch_diagnosis_codes[ind].append([n_diagnosis_codes-1])\n",
        "    return batch_diagnosis_codes, batch_time_step\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    r\"\"\"\n",
        "        This criterion is a implemenation of Focal Loss, which is proposed in\n",
        "        Focal Loss for Dense Object Detection.\n",
        "            Loss(x, class) = - \\alpha (1-softmax(x)[class])^gamma \\log(softmax(x)[class])\n",
        "        The losses are averaged across observations for each minibatch.\n",
        "        Args:\n",
        "            alpha(1D Tensor, Variable) : the scalar factor for this criterion\n",
        "            gamma(float, double) : gamma > 0; reduces the relative loss for well-classiﬁed examples (p > .5),\n",
        "                                   putting more focus on hard, misclassiﬁed examples\n",
        "            size_average(bool): By default, the losses are averaged over observations for each minibatch.\n",
        "                                However, if the field size_average is set to False, the losses are\n",
        "                                instead summed for each minibatch.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, class_num, alpha=None, gamma=2, size_average=True):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        if alpha is None:\n",
        "            self.alpha = Variable(torch.ones(class_num, 1))\n",
        "        else:\n",
        "            if isinstance(alpha, Variable):\n",
        "                self.alpha = alpha\n",
        "            else:\n",
        "                self.alpha = Variable(alpha)\n",
        "        self.gamma = gamma\n",
        "        self.class_num = class_num\n",
        "        self.size_average = size_average\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        N = inputs.size(0)\n",
        "        C = inputs.size(1)\n",
        "        P = nn.functional.softmax(inputs)\n",
        "\n",
        "        class_mask = inputs.data.new(N, C).fill_(0)\n",
        "        class_mask = Variable(class_mask)\n",
        "        ids = targets.view(-1, 1)\n",
        "        class_mask.scatter_(1, ids.data, 1.)\n",
        "\n",
        "        if inputs.is_cuda and not self.alpha.is_cuda:\n",
        "            self.alpha = self.alpha.cuda()\n",
        "        alpha = self.alpha[ids.data.view(-1)]\n",
        "\n",
        "        probs = (P * class_mask).sum(1).view(-1, 1)\n",
        "\n",
        "        log_p = probs.log()\n",
        "\n",
        "        batch_loss = -alpha * (torch.pow((1 - probs), self.gamma)) * log_p\n",
        "\n",
        "        if self.size_average:\n",
        "            loss = batch_loss.mean()\n",
        "        else:\n",
        "            loss = batch_loss.sum()\n",
        "        return loss"
      ],
      "metadata": {
        "id": "sK7kb8eKaITY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "model training and testing function"
      ],
      "metadata": {
        "id": "EXSx6QC9H-jm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "l4QciC7gZO2k"
      },
      "outputs": [],
      "source": [
        "def train_model(training_file='training_file',\n",
        "                testing_file='testing_file',\n",
        "                n_diagnosis_codes=10000,\n",
        "                n_labels=2,\n",
        "                batch_size=100,\n",
        "                dropout_rate=0.5,\n",
        "                L2_reg=0.001,\n",
        "                n_epoch=1000,\n",
        "                log_eps=1e-8,\n",
        "                visit_size=512,\n",
        "                hidden_size=256,\n",
        "                use_gpu=False,\n",
        "                model_name='',\n",
        "                disease = 'hf',\n",
        "                code2id = None,\n",
        "                running_data='',\n",
        "                gamma=0.5,\n",
        "                model_file = None,\n",
        "                layer=1):\n",
        "    options = locals().copy()\n",
        "\n",
        "    model = model_file(n_diagnosis_codes, batch_size, options)\n",
        "    focal_loss = FocalLoss(2, gamma=gamma)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay = options['L2_reg'])\n",
        "\n",
        "    train, test = load_data(training_file, testing_file)\n",
        "    n_batches = int(np.ceil(float(len(train[0])) / float(batch_size)))\n",
        "\n",
        "    max_len = 50\n",
        "    best_parameters_file = ''\n",
        "    if use_gpu:\n",
        "        model.cuda()\n",
        "    model.train()\n",
        "    for epoch in range(n_epoch):\n",
        "        cost_vector = []\n",
        "        start_time = time.time()\n",
        "        samples = random.sample(range(n_batches), n_batches)\n",
        "        counter = 0\n",
        "\n",
        "        for index in samples:\n",
        "            batch_diagnosis_codes = train[0][batch_size * index: batch_size * (index + 1)]\n",
        "            batch_time_step = train[2][batch_size * index: batch_size * (index + 1)]\n",
        "            batch_diagnosis_codes, batch_time_step = adjust_input(batch_diagnosis_codes, batch_time_step, max_len, n_diagnosis_codes)\n",
        "            batch_labels = train[1][batch_size * index: batch_size * (index + 1)]\n",
        "            lengths = np.array([len(seq) for seq in batch_diagnosis_codes])\n",
        "            maxlen = np.max(lengths)\n",
        "            predictions, labels, self_attention = model(batch_diagnosis_codes, batch_time_step, batch_labels, options, maxlen)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            loss = focal_loss(predictions, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            cost_vector.append(loss.cpu().data.numpy())\n",
        "\n",
        "    model.eval()\n",
        "    n_batches = int(np.ceil(float(len(test[0])) / float(batch_size)))\n",
        "    y_true = np.array([])\n",
        "    y_pred = np.array([])\n",
        "    for index in range(n_batches):\n",
        "        batch_diagnosis_codes = test[0][batch_size * index: batch_size * (index + 1)]\n",
        "        batch_time_step = test[2][batch_size * index: batch_size * (index + 1)]\n",
        "        batch_diagnosis_codes, batch_time_step = adjust_input(batch_diagnosis_codes, batch_time_step, max_len, n_diagnosis_codes)\n",
        "        batch_labels = test[1][batch_size * index: batch_size * (index + 1)]\n",
        "        lengths = np.array([len(seq) for seq in batch_diagnosis_codes])\n",
        "        maxlen = np.max(lengths)\n",
        "        logit, labels, self_attention = model(batch_diagnosis_codes, batch_time_step, batch_labels, options, maxlen)\n",
        "\n",
        "        if use_gpu:\n",
        "            prediction = torch.max(logit, 1)[1].view((len(labels),)).data.cpu().numpy()\n",
        "            labels = labels.data.cpu().numpy()\n",
        "        else:\n",
        "            prediction = torch.max(logit, 1)[1].view((len(labels),)).data.numpy()\n",
        "            labels = labels.data.numpy()\n",
        "\n",
        "        y_true = np.concatenate((y_true, labels))\n",
        "        y_pred = np.concatenate((y_pred, prediction))\n",
        "\n",
        "    accuary = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred)\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    roc_auc = roc_auc_score(y_true, y_pred)\n",
        "    print(accuary, precision, recall, f1, roc_auc)\n",
        "    return (accuary, precision, recall, f1, roc_auc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "main function and hyperparameter etc."
      ],
      "metadata": {
        "id": "Fidp3sAvIGNw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# parameters\n",
        "batch_size = 50\n",
        "dropout_rate = 0.5\n",
        "L2_reg = 1e-3\n",
        "log_eps = 1e-8\n",
        "n_epoch = 20\n",
        "n_labels = 2  # binary classification\n",
        "visit_size = 256 # size of input embedding\n",
        "hidden_size = 256 # size of hidden layer\n",
        "gamma = 0.0 # setting for Focal Loss, when it's zero, it's equal to standard cross loss\n",
        "use_gpu = True\n",
        "layer = 1 # layer of Transformer\n",
        "model_choice = ['TransformerTime', 'TransformerLT', 'TransformerGT']\n",
        "disease_list = ['hf_sample', 'hf', 'COPD'] \n",
        "for model in model_choice:\n",
        "  model_file = eval(model)\n",
        "  for disease in disease_list:\n",
        "      model_name = 'tran_%s_%s_L%d_wt_1e-4_focal%.2f' % (model, disease, layer, gamma)\n",
        "      print(model_name)\n",
        "      log_file = 'results/' + model_name + '.txt'\n",
        "      path = './'\n",
        "      trianing_file = path + disease + '_training.pickle'\n",
        "      testing_file = path + disease + '_testing.pickle'\n",
        "\n",
        "      dict_file = './' + disease + '_code2idx.pickle'\n",
        "      code2id = pickle.load(open(dict_file, 'rb'))\n",
        "      n_diagnosis_codes = len(pickle.load(open(dict_file, 'rb'))) + 1\n",
        "\n",
        "      results = []\n",
        "      for k in range(20):\n",
        "          accuary, precision, recall, f1, roc_auc = train_model(trianing_file,\n",
        "                                                                testing_file, n_diagnosis_codes, n_labels,\n",
        "                                                                batch_size, dropout_rate,\n",
        "                                                                L2_reg, n_epoch, log_eps, visit_size, hidden_size,\n",
        "                                                                use_gpu, model_name, disease=disease, code2id=None,\n",
        "                                                                gamma=gamma, layer=layer, model_file=model_file)\n",
        "          results.append([accuary, precision, recall, f1, roc_auc])\n",
        "\n",
        "      results = np.array(results)\n",
        "      print(np.mean(results, 0))\n",
        "      print(np.std(results, 0))"
      ],
      "metadata": {
        "id": "UxrSXKIiZoO-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "outputId": "b53826ca-d884-44ef-fd3a-8733f805feeb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tran_TransformerGT_hf_L1_wt_1e-4_focal0.00\n",
            "0.8719329742669061 0.9811320754716981 0.49760765550239233 0.6603174603174603 0.7472076585572616\n",
            "0.9072411729503291 0.8065268065268065 0.8277511961722488 0.8170011806375443 0.8807550873119824\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-e6e999e57bb2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m                                                                 \u001b[0mL2_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_eps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisit_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                                                                 \u001b[0muse_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisease\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisease\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode2id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                                                                 gamma=gamma, layer=layer, model_file=model_file)\n\u001b[0m\u001b[1;32m     39\u001b[0m           \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maccuary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroc_auc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-210ff4506736>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(training_file, testing_file, n_diagnosis_codes, n_labels, batch_size, dropout_rate, L2_reg, n_epoch, log_eps, visit_size, hidden_size, use_gpu, model_name, disease, code2id, running_data, gamma, model_file, layer)\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfocal_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mcost_vector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    151\u001b[0m                    \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                    \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                    maximize=group['maximize'])\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "eGFDc4V6fBLO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}